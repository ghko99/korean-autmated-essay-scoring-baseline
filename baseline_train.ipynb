{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "604ef0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from baseline_embedding import get_dataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import time\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import gc\n",
    "from sklearn.metrics import cohen_kappa_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5d9a842",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import config\n",
    "\n",
    "args = config['aihub_v1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49838058",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11b27a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedded_essay(essays, is_train=True):        \n",
    "    # embedded_essay_raw = pd.read_csv(os.path.join(args['emb_file_path'], f\"{args['train_dataset_path'].split('/')[1]}_{'train' if is_train else 'valid'}_{'notlabeled' if args['is_topic_label'] == False else 'labeled'}.csv\"), encoding='cp949')\n",
    "    embedded_essay_raw = pd.read_csv(os.path.join(args['emb_file_path'], f\"emb_feat_{'train' if is_train else 'valid'}_{'notlabeled' if args['is_topic_label'] == False else 'labeled'}.csv\"), encoding='cp949')\n",
    "    print(embedded_essay_raw.shape)\n",
    "    embedded_essay = []\n",
    "    tmp_ix = 0\n",
    "    for ix, essay_raw in enumerate(essays):\n",
    "        tmp_len = len(essay_raw)\n",
    "        essay = embedded_essay_raw[tmp_ix:tmp_ix + tmp_len]\n",
    "        embedded_essay.append(essay)\n",
    "        tmp_ix += tmp_len\n",
    "    return embedded_essay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bfd5decb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(y_sent_pred, y_test):\n",
    "    metrics = {}\n",
    "    all_kappas = []\n",
    "    for i in range(len(args['rubric'])):\n",
    "        metrics[args['rubric'][i]] = {}\n",
    "        y_pred = y_sent_pred[:, i]\n",
    "        y_true = y_test[:, i]\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        kappa = cohen_kappa_score(y_true, y_pred, weights='quadratic')\n",
    "        metrics[args['rubric'][i]]['accuracy'] = accuracy\n",
    "        metrics[args['rubric'][i]]['kappa'] = kappa\n",
    "        all_kappas.append(kappa)\n",
    "\n",
    "    metrics['overall'] = {}\n",
    "    overall_accuracy = accuracy_score(y_test.flatten(), y_sent_pred.flatten())\n",
    "    overall_kappa = np.mean(all_kappas)\n",
    "    metrics['overall']['accuracy'] = overall_accuracy\n",
    "    metrics['overall']['kappa'] = overall_kappa\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8fbfb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUScoreModule(nn.Module):\n",
    "    def __init__(self,output_dim,hidden_dim, dropout=0.5):\n",
    "        super(GRUScoreModule, self).__init__()\n",
    "        self.gru = nn.GRU(768,hidden_dim, dropout=dropout, batch_first=True, bidirectional=True)        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_dim*2, output_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x, _ = self.gru(x)\n",
    "        \n",
    "        x = x[:, -1, :]  # Use the output of the last time step\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fadf9432",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EssayDataset(Dataset):\n",
    "    def __init__(self, embedded_essays, labels):\n",
    "        self.embedded_essays = embedded_essays\n",
    "        self.embedded_essays = torch.tensor(pad_sequences(embedded_essays, maxlen=128, padding='pre', dtype='float32'), dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.embedded_essays[idx], self.labels[idx]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8404be4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(485014, 768)\n",
      "(68609, 768)\n"
     ]
    }
   ],
   "source": [
    "train_essay, valid_essay, train_y, valid_y = get_dataset()\n",
    "train_embedded_essay = get_embedded_essay(train_essay, is_train=True)\n",
    "valid_embedded_essay = get_embedded_essay(valid_essay, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3ce4785",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = EssayDataset(train_embedded_essay, train_y)\n",
    "valid_dataset = EssayDataset(valid_embedded_essay, valid_y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44ea91f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b25fd970",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\khko9\\anaconda3\\envs\\rebellion\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:88: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "n_outputs = len(args['rubric'])\n",
    "\n",
    "dropout = 0.5\n",
    "learning_rate = 0.001\n",
    "n_epochs = 100\n",
    "\n",
    "model = GRUScoreModule(output_dim=n_outputs,hidden_dim=128, dropout=dropout).cuda()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a474b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 0.0568, Val Loss: 0.0456, Time Elapsed: 6.8013\n",
      "Epoch 2/100, Train Loss: 0.0284, Val Loss: 0.0394, Time Elapsed: 5.4532\n",
      "Epoch 3/100, Train Loss: 0.0241, Val Loss: 0.0369, Time Elapsed: 5.2994\n",
      "Epoch 4/100, Train Loss: 0.0217, Val Loss: 0.0356, Time Elapsed: 5.5189\n",
      "Epoch 5/100, Train Loss: 0.0205, Val Loss: 0.0346, Time Elapsed: 5.4959\n",
      "Epoch 6/100, Train Loss: 0.0198, Val Loss: 0.0339, Time Elapsed: 5.3946\n",
      "Epoch 7/100, Train Loss: 0.0190, Val Loss: 0.0351, Time Elapsed: 5.4450\n",
      "Epoch 8/100, Train Loss: 0.0184, Val Loss: 0.0338, Time Elapsed: 5.5432\n",
      "Epoch 9/100, Train Loss: 0.0180, Val Loss: 0.0316, Time Elapsed: 5.5274\n",
      "Epoch 10/100, Train Loss: 0.0176, Val Loss: 0.0333, Time Elapsed: 5.4077\n",
      "Epoch 11/100, Train Loss: 0.0172, Val Loss: 0.0331, Time Elapsed: 5.8063\n",
      "Epoch 12/100, Train Loss: 0.0168, Val Loss: 0.0310, Time Elapsed: 6.6663\n",
      "Epoch 13/100, Train Loss: 0.0166, Val Loss: 0.0317, Time Elapsed: 7.8648\n",
      "Epoch 14/100, Train Loss: 0.0164, Val Loss: 0.0301, Time Elapsed: 5.8970\n",
      "Epoch 15/100, Train Loss: 0.0161, Val Loss: 0.0302, Time Elapsed: 5.6284\n",
      "Epoch 16/100, Train Loss: 0.0159, Val Loss: 0.0314, Time Elapsed: 5.4291\n",
      "Epoch 17/100, Train Loss: 0.0156, Val Loss: 0.0324, Time Elapsed: 5.3839\n",
      "Epoch 18/100, Train Loss: 0.0154, Val Loss: 0.0302, Time Elapsed: 5.6158\n",
      "Epoch 19/100, Train Loss: 0.0153, Val Loss: 0.0306, Time Elapsed: 5.3865\n",
      "Epoch 20/100, Train Loss: 0.0150, Val Loss: 0.0314, Time Elapsed: 5.5823\n",
      "Epoch 21/100, Train Loss: 0.0149, Val Loss: 0.0299, Time Elapsed: 5.4722\n",
      "Epoch 22/100, Train Loss: 0.0146, Val Loss: 0.0303, Time Elapsed: 5.6602\n",
      "Epoch 23/100, Train Loss: 0.0144, Val Loss: 0.0305, Time Elapsed: 5.5057\n",
      "Epoch 24/100, Train Loss: 0.0143, Val Loss: 0.0310, Time Elapsed: 5.5693\n",
      "Epoch 25/100, Train Loss: 0.0142, Val Loss: 0.0302, Time Elapsed: 5.4754\n",
      "Epoch 26/100, Train Loss: 0.0140, Val Loss: 0.0307, Time Elapsed: 5.5185\n",
      "Epoch 27/100, Train Loss: 0.0138, Val Loss: 0.0302, Time Elapsed: 5.5354\n",
      "Epoch 28/100, Train Loss: 0.0137, Val Loss: 0.0303, Time Elapsed: 5.8388\n",
      "Epoch 29/100, Train Loss: 0.0134, Val Loss: 0.0290, Time Elapsed: 5.4099\n",
      "Epoch 30/100, Train Loss: 0.0134, Val Loss: 0.0305, Time Elapsed: 5.6133\n",
      "Epoch 31/100, Train Loss: 0.0132, Val Loss: 0.0309, Time Elapsed: 5.4731\n",
      "Epoch 32/100, Train Loss: 0.0132, Val Loss: 0.0311, Time Elapsed: 5.4512\n",
      "Epoch 33/100, Train Loss: 0.0128, Val Loss: 0.0305, Time Elapsed: 5.4325\n",
      "Epoch 34/100, Train Loss: 0.0127, Val Loss: 0.0310, Time Elapsed: 5.4663\n",
      "Epoch 35/100, Train Loss: 0.0125, Val Loss: 0.0291, Time Elapsed: 5.5895\n",
      "Epoch 36/100, Train Loss: 0.0122, Val Loss: 0.0317, Time Elapsed: 5.4770\n",
      "Epoch 37/100, Train Loss: 0.0123, Val Loss: 0.0310, Time Elapsed: 5.3197\n",
      "Epoch 38/100, Train Loss: 0.0122, Val Loss: 0.0311, Time Elapsed: 5.3372\n",
      "Epoch 39/100, Train Loss: 0.0119, Val Loss: 0.0311, Time Elapsed: 5.2444\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "patience = 10\n",
    "train_loss_list = []\n",
    "val_loss_list = []\n",
    "best_val_loss = float('inf')\n",
    "early_stopping_counter = 0\n",
    "prev_time = time.time()\n",
    "set_seed(42)\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for inputs,labels in train_loader:\n",
    "        inputs ,labels = inputs.cuda(), labels.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)        \n",
    "        loss = criterion(outputs, labels)\n",
    "            \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    model.eval()\n",
    "    all_outputs = []\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in valid_loader:\n",
    "            inputs, labels = inputs.cuda(),labels.cuda()\n",
    "            outputs = model(inputs)            \n",
    "            loss = criterion(outputs, labels)\n",
    "            all_outputs.extend(outputs.cpu().numpy())\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    val_loss /= len(valid_loader)\n",
    "    train_loss_list.append(train_loss)\n",
    "    val_loss_list.append(val_loss)\n",
    "    print(f'Epoch {epoch+1}/{n_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Time Elapsed: {time.time() - prev_time:.4f}')\n",
    "    prev_time = time.time()\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_outputs = np.array(all_outputs)\n",
    "        if not os.path.exists('./model'):\n",
    "            os.makedirs('./model')\n",
    "        torch.save(model.state_dict(), './model/kobert_model.pth')\n",
    "        best_val_loss = val_loss\n",
    "        early_stopping_counter = 0\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "        if early_stopping_counter >= patience:\n",
    "            print(\"Early stopping\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee96bd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_outputs\n",
    "y_test = np.array(valid_y)\n",
    "y_test = np.rint(y_test*len(args['num_range'])).astype(int)\n",
    "y_pred = np.rint(y_pred*len(args['num_range'])).astype(int)\n",
    "y_pred = np.clip(y_pred, min(y_test), max(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7dfe7e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exp1': {'accuracy': 0.6044700304774805, 'kappa': 0.28124239377744853},\n",
       " 'exp2': {'accuracy': 0.6410430071114122, 'kappa': 0.33612429122508114},\n",
       " 'exp3': {'accuracy': 0.7126650863528615, 'kappa': 0.8688147490311131},\n",
       " 'org1': {'accuracy': 0.536065018625127, 'kappa': 0.3406097226796083},\n",
       " 'org2': {'accuracy': 0.75330172705723, 'kappa': 0.8982884062761548},\n",
       " 'org3': {'accuracy': 0.6796478157805621, 'kappa': 0.8575876170944874},\n",
       " 'org4': {'accuracy': 0.7260413139180495, 'kappa': 0.659550517719069},\n",
       " 'con1': {'accuracy': 0.6366407043684389, 'kappa': 0.355000063521442},\n",
       " 'con2': {'accuracy': 0.6134439552996952, 'kappa': 0.09285019234206038},\n",
       " 'con3': {'accuracy': 0.7571960717913986, 'kappa': 0.9027817107688751},\n",
       " 'con4': {'accuracy': 0.5951574669827294, 'kappa': 0.4233534435385514},\n",
       " 'overall': {'accuracy': 0.6596065634331805, 'kappa': 0.5469275552703536}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "metrics = compute_metrics(y_pred,y_test)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d17b09c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 2, ..., 2, 3, 3])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.flatten()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rebellion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
